{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "https://towardsdatascience.com/andwritten-digit-mnist-pytorch-977b5338e627"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 4\n",
    "epochs = 5\n",
    "n_workers = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the MNIST dataset. Normalizing image values between -1 and 1\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "\n",
    "# Loading data to dataloader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=n_workers)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=n_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:4\n"
     ]
    }
   ],
   "source": [
    "# Showing image example\n",
    "def show_img(img):\n",
    "    img = img/2 +0.5\n",
    "    np_img = img.numpy()\n",
    "    plt.imshow(np.transpose(np_img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "random_idx =  random.randint(0, len(trainset))\n",
    "image, label = trainset[random_idx]\n",
    "show_img(image)\n",
    "print(f'label:{label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max value:  tensor(1.)\n",
      "min value:  tensor(-1.)\n"
     ]
    }
   ],
   "source": [
    "print('max value: ', trainset[random_idx][0].max())\n",
    "print('min value: ', trainset[random_idx][0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 28, 28]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Explore shape of data\n",
    "X_train, y_train = next(iter(trainloader))\n",
    "print(X_train.shape, y_train.shape)\n",
    "# # print the class of the image\n",
    "# print(' '.join('%s' % classes[labels[j]] for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorically encoding the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 7, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "model= Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy (y_true, y_pred):\n",
    "    return (y_pred == y_true).sum().item()/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    final_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get input, and send to device\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        # zero the gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs) \n",
    "        _, pred_labels = torch.max(outputs.data, 1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss every 1000 steps\n",
    "        if (i+1) % 1000 == 0:\n",
    "            train_acc = get_accuracy(labels, pred_labels)\n",
    "            print(f'Step [{i+1}/{len(trainloader)}]: Loss = {loss.item()} - Accuracy = {train_acc}')\n",
    "\n",
    "        # save loss\n",
    "        final_loss +=loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model\n",
    "model_saving_p = './mnist_net.pth'\n",
    "torch.save(model.state_dict(), model_saving_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(model_saving_p))\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        _, pred_labels = torch.max(outputs.data, 1)\n",
    "        total+= 1#labels.size(0)\n",
    "        correct+= get_accuracy(labels, pred_labels)\n",
    "        \n",
    "        # print(f'correct / total: {correct} / {total}')\n",
    "print(f'Accuracy on the test set: {correct / total}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95684bf35b52fd355f8b64198f517869e308ec096e50f26d143db610b46fcfbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
